{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "municipal-guatemala",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a8b253cea124309dc7872a31b41818e",
     "grade": false,
     "grade_id": "cell-b038e38b5e3072a9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# IST 718: Big Data Analytics\n",
    "\n",
    "- Professor: Daniel Acuna <deacuna@syr.edu>\n",
    "\n",
    "## General instructions:\n",
    "\n",
    "- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n",
    "- You can put the homework files anywhere you want in your https://jupyterhub.ischool.syr.edu/ workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n",
    "- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n",
    "- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n",
    "- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n",
    "`Kernel`$\\rightarrow$`Restart and Run All`). \n",
    "- Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the packages needed for this part\n",
    "# create spark and sparkcontext objects\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "from pyspark.ml import feature, regression, Pipeline, pipeline, evaluation, tuning, clustering\n",
    "from pyspark.sql import types, Row, functions as fn\n",
    "from pyspark import sql\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-steel",
   "metadata": {},
   "source": [
    "# Part 2: Feature engineering and recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-bundle",
   "metadata": {},
   "source": [
    "In this project, we are going to study a dataset of Spotify songs for which we have a number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-beatles",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3256f5c995b855ba7c4b341b0a9426bd",
     "grade": false,
     "grade_id": "cell-a3d100eed4c0180b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "spotify = spark.read.csv('spotify_songs.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-samoa",
   "metadata": {},
   "source": [
    "## Question 1. (10 pts)\n",
    "First, we will try to understand how the duration, tempo, and key are related to danceability. Unfortunately, each of these features is in different scales, and the feature key is categorical.\n",
    "\n",
    "Create a pipeline called `featurize` that performs the following feature engineering steps\n",
    "- Standardizes and `duration_ms` and `tempo` (you have to combine `feature.VectorAssembler` with `feature.StandardScaler`)\n",
    "- Create dummy variables for `key` (you have to use `feature.OneHotEncoder`. This encoder uses the *last category* as the baseline. Be careful when interpreting it)\n",
    "\n",
    "You have to create a last step in this featurizer that combines the two kinds of engineered features into a column called `features` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-christianity",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50c326766af70da4d7275d69026ccc74",
     "grade": false,
     "grade_id": "cell-fc7d6ee4615ba773",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create pipeline to produce principal components of data\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the featurizer here\n",
    "featurize.transform(spotify).select('features').first().features.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-assumption",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f27ecd1cde35df50b7ce1903a01cc194",
     "grade": true,
     "grade_id": "cell-b2314cd3e1df9f8c",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "assert type(featurize) == pipeline.PipelineModel\n",
    "assert feature.StandardScalerModel in list(map(type, featurize.stages))\n",
    "assert feature.OneHotEncoderModel in list(map(type, featurize.stages))\n",
    "assert feature.VectorAssembler in list(map(type, featurize.stages))\n",
    "assert len(featurize.transform(spotify).select('features').first().features.toArray()) == 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-campaign",
   "metadata": {},
   "source": [
    "## Question 2: (15 pts)\n",
    "We will now compare a model without feature engineering to one with feature engineering.\n",
    "\n",
    "First, create a vanilla pipeline that takes `duration`, `tempo`, and `key` without any feature engineering and assembles them into a column `features`. Call this pipeline `vanilla_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-internet",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "14928b99972399ffdf3880d826533b10",
     "grade": false,
     "grade_id": "cell-f34d0f48df586706",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create pipeline for vanilla featurizer\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your pipeline\n",
    "vanilla_features.transform(spotify).first().features.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-jamaica",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5630e8813c0e4e13d2868896b6e0a45d",
     "grade": true,
     "grade_id": "cell-8f3f865be20d6d07",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "assert type(vanilla_features) == pipeline.PipelineModel\n",
    "assert len(vanilla_features.transform(spotify).select('features').first().features.toArray()) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-warner",
   "metadata": {},
   "source": [
    "Now, create two regression pipeline estimators (don't fit them) `model_fe` and `model_vanilla` where `model_fe` uses the featurizer from Question 1 to create the features and `model_vanilla` creates the features using the previous pipeline. Remember that you are predicting `danceability`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-stations",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aafc543490b92a5d6f0f5fadc4739c33",
     "grade": false,
     "grade_id": "cell-567bc2f06def8269",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create pipeline for models\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-appeal",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c212595b4d212c5c633204fceee8c8d1",
     "grade": true,
     "grade_id": "cell-b309ca11d308d35f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "assert type(model1) == pipeline.Pipeline\n",
    "assert len(model1.getStages()) == 2\n",
    "assert type(model2) == pipeline.Pipeline\n",
    "assert len(model2.getStages()) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-novelty",
   "metadata": {},
   "source": [
    "With the code below, we will evaluate the performance of each of the models and print them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_evaluator = evaluation.RegressionEvaluator(labelCol='danceability', metricName='rmse')\n",
    "training_df, validation_df = spotify.randomSplit([0.8, 0.2], seed=0)\n",
    "\n",
    "print(\"RMSE model 1: \", regression_evaluator.evaluate(model1.fit(training_df).transform(validation_df)))\n",
    "print(\"RMSE model 2: \", regression_evaluator.evaluate(model2.fit(training_df).transform(validation_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-function",
   "metadata": {},
   "source": [
    "**(5 pts)** Based on the results above, what can you say about the model with feature engineering. Is there are big difference in performance? If not, why would it be worth doing feature engineering anyway? Answer below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-rapid",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c5e67264d2b3b2b55dd06d05097e98c0",
     "grade": true,
     "grade_id": "cell-e0b6d5e1cc91f239",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-foundation",
   "metadata": {},
   "source": [
    "## Question 3: (25 pts) Clustering\n",
    "\n",
    "We will now make recommendation of songs based on k-means. Create a pipeline where you fit a 10-cluster KMeans to the following features **after standardization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-violin",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cab49be872531431a1b62e5a016af39",
     "grade": false,
     "grade_id": "cell-891657c21c2e4e7b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "feature_list = ['acousticness',\n",
    " 'danceability',\n",
    " 'duration_ms',\n",
    " 'energy',\n",
    " 'instrumentalness',\n",
    " 'key',\n",
    " 'liveness',\n",
    " 'loudness',\n",
    " 'mode',\n",
    " 'speechiness',\n",
    " 'tempo',\n",
    " 'time_signature',\n",
    " 'valence']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-understanding",
   "metadata": {},
   "source": [
    "Name the pipeline `spotify_clustering` and make sure that the `KMeans` model has a prediction column called `cluster`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-amino",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0dd885a2340d06427964dd015d46107",
     "grade": false,
     "grade_id": "cell-20dba717da0f0efa",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create pipeline spotify_clustering\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-memory",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18768d7de3b91c38df3b776a70372512",
     "grade": true,
     "grade_id": "cell-f38f573e553928b6",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "assert type(spotify_clustering) == pipeline.PipelineModel\n",
    "assert feature.StandardScalerModel in set(map(type, spotify_clustering.stages))\n",
    "assert spotify_clustering.stages[-1].extractParamMap()[(spotify_clustering.stages[-1].k)] == 10\n",
    "assert spotify_clustering.stages[-1].extractParamMap()[(spotify_clustering.stages[-1].predictionCol)] == 'cluster'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-valentine",
   "metadata": {},
   "source": [
    "As you all know, the professor is a big fan of Meat Loaf (the artists, obviously) and his song \"I will do anything for love (But I won't do that)\" because it is close to the professor's mantra: \"I will do anything for data (But I won't overfit)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_loaf = spotify.where(fn.col('artist') == \"Meat Loaf\")\n",
    "print(meat_loaf.first().song_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-andorra",
   "metadata": {},
   "source": [
    "In the cell below, extract the cluster number of Meat Loaf's song and store it in `meat_loaf_cluster_id`. Also, create a Spark DataFrame `similar_songs` with the songs from that Meat Loaf's cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-testing",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa0466b5e9939310027a4f1872d11733",
     "grade": false,
     "grade_id": "cell-061eec47df5a532f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create variable meat_loaf_cluster_id and dataframe similar_songs\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the following code to find suggestions\n",
    "similar_songs.select('song_title', 'artist').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-horizon",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a97a79772c55aa504eaf41cd968dff3f",
     "grade": true,
     "grade_id": "cell-83e735291aaacb75",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 10 pts\n",
    "assert 0 <= meat_loaf_cluster_id <= 9\n",
    "assert similar_songs.count() < spotify.count()\n",
    "assert similar_songs.where('cluster == 0')\n",
    "assert similar_songs.where('cluster = ' + str(meat_loaf_cluster_id)).where('artist = \"Meat Loaf\"').count() == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-rating",
   "metadata": {},
   "source": [
    "One of the problems wih `KMeans` is that clusters are sometimes unbalanced. Analyze the clustering by creating a dataframe `cluster_analysis` where the first column is the cluster (`cluster`) and the second is the number of song for such cluster (`n_songs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-graduation",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e89682022d1d3177d29b6c2a17998353",
     "grade": false,
     "grade_id": "cell-da84475ea6bfb18b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# create dataframe cluster_analysis\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "(cluster_analysis\n",
    " .toPandas()\n",
    " .sort_values('n_songs', ascending=False)\n",
    " .reset_index()\n",
    " .n_songs.plot(y='n_songs', kind='bar')\n",
    ");\n",
    "plt.xlabel('cluster rank')\n",
    "plt.ylabel('# songs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-subcommittee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8de0b836e673e43f4039869d443a622f",
     "grade": true,
     "grade_id": "cell-b44b2a79f3452fd4",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 5 pts\n",
    "assert cluster_analysis.count() == 10\n",
    "assert type(cluster_analysis) == sql.dataframe.DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
